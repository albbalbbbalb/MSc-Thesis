We introduce the Lempel-Ziv complexity (LZC) as described in \cite{LZ76}. LZC operates on finite length sequences of symbols by applying a compression algorithm, the complexity of the original sequence is then quantified by the result of the compression.

We find it easiest to include the code of the implementation. The code is provided by Mediano and Rosas \cite{MedianoRosas2019} and they attribute the implementation to \cite{Kaspar1987EasilyCM} which is a nice use case and provides a good example of the algorithm.

\input{lempelzivcode.tex}

Loosely, we have two pointers ascending through the list, the left pointer is at index $i+k-1$, and the right pointer is at index $\ell+k-1$, at each iteration the pointers move depending on what symbol they see at their index. If they see the same symbol, the size of the window $k$ is incremented by 1, so both pointers shift, if not then $i$ is incremented by 1, i.e., only the left pointer shifts. As this happens we update the longest window size $k_\text{max}$ that we encounter, this corresponds to the size of the longest word that can be reconstructed starting at index $\ell$ using only the words that appear before $\ell$. Once $i=\ell$, we increment the number of words, the right pointer is pushed forward by $k_\text{max}$, that is, $\ell$ becomes $\ell+k_\text{max}$. The process repeats until the right pointer reaches the end of the list or if the current window size looks past the end of the list.

We provide examples below. The $\cdot$ is used as a word delimiter, the underline indicates the window at the left pointer, and the overline indicates the one at the right pointer. We only show the longest window that was achieved, notice the index of the longest window is not necessarily unique, and the window ends at the first symbol that differs. 
\begin{align*}
01011010001101110010
&\xrightarrow{(1)}
\underline0\cdot\overline{1}011010001101110010\\
&\xrightarrow{(2)}
\underline{0\cdot1\,\cdot\,}\overline{\underline{0}}\overline{11}010001101110010 \\
&\xrightarrow{(3)}
\underline{0\cdot1\cdot01}1\cdot\overline{0100}01101110010 \\
&\xrightarrow{(4)}
0\cdot1\cdot\underline{011\cdot010}0\cdot\overline{011011}10010 \\
&\xrightarrow{(5)}
0\cdot1\cdot011\cdot0\underline{100\cdot0}11011\cdot\overline{1001}0 \\
&\xrightarrow{(6)}
\underline{0\cdot1}\cdot011\cdot0100\cdot011011\cdot1001\cdot\overline{0\text{  }},
\end{align*}
the number of words is 7, so the LZC of this sequence is $7$. Let's consider another example with repetition:
\begin{align*}
01101101101101101101
&\xrightarrow{(1)}
\underline0\cdot\overline{1}101101101101101101\\
&\xrightarrow{(2)}
0\cdot\underline{1\,\cdot\,}\overline{\underline{1}}\overline{0}1101101101101101\\
&\xrightarrow{(3)}
0\cdot\underline{1\cdot10\,\cdot\,}\underline{\overline{11011011011011}}\overline{01\text{  }},
\end{align*}
the number of words is 4, so the LZC is 4. Notice how the two examples have the same number of digits but the one with less repetition has greater complexity. We consider one final example:
\begin{align*}
01010101010101010101
&\xrightarrow{(1)}
\underline{0}\cdot\overline{1}010101010101010101\\
&\xrightarrow{(2)}
\underline{0\cdot1\,\cdot\,}\underline{\overline{01010101010101010}}\overline{1\text{  }},
\end{align*}
and we see the LZ complexity is 3. Notice that even though the last two examples are periodic, one has greater LZC, since the repeating word 011 is longer than 01. So, LZC not only differentiates between periodic and aperiodic sequences, it also distinguishes between periodic sequences of different period.

All examples were with the alphabet $\{0,1\}$ but this can be done with an arbitrary alphabet. It's interesting to note that LZC also supports infinite alphabets. Since we consider finite sequences, there is an upper bound for LZC, namely, the length of the sequence. We have yet to find a drawback in the setup.

The LZC is suited for comparing sequences of the same length. We can see this is the case by comparing $010$ and $010101\dots$, the latter can be made arbitrarily long and the two LZC will be still the same. Yet, this is meaningless, since the LZC of a short sequence will be comparable to its length.

Now, suppose we consider sequences generated by \eqref{eq:magnetichamiltonian} using the procedure as discussed in the previous section. In this case the sequences encode information about trajectories of a dynamical system. We can apply LZC to these sequences to distinguish between periodic and aperiodic trajectories, though, since we use LZC for finite length sequences, we only compare trajectories up to a finite time horizon. Many structures in dynamical systems rely on infinite times, for example, limit cycles, so LZC may or may not detect them. Likewise, there exist systems with trajectories that can stay close to limit cycles for arbitrarily long times before diverging, so LZC could not detect this behavior unless a longer time horizon is chosen. 

In fact, we see this type of behavior in \cref{fig:sensitive_trajectory}: if we took symbols up until the trajectory just jumped out from the 4 bumps, then the LZC would be very low for the length of the sequence, yet clearly the trajectory is not quasi-periodic. Focusing on the trajectories in \cref{fig:weakcomparison}, we see that another issue can arise: the chosen time horizon could be shorter than the period of the (quasi)-periodic trajectory, LZC could label such a trajectory as complex despite the ``macroscopic'' structure that is apparent with the human eye. LZC would also struggle with eventually periodic sequences, if the periodic behavior arrives too late, then the LZC ranks the trajectory complex.